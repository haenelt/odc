{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create maps in dense freesurfer space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "import numpy as np\n",
    "from nibabel.freesurfer.io import read_geometry, read_label\n",
    "from fmri_tools.surface.filter import LaplacianGaussian\n",
    "from fmri_tools.surface.mesh import Mesh\n",
    "from fmri_tools.io.surf import (\n",
    "    read_mgh, write_mgh, write_label, patch_as_mesh, mgh_to_patch, curv_to_patch, \n",
    "    label_to_patch\n",
    "    )\n",
    "from src.config import DIR_BASE, SESSION\n",
    "from src.helper import get_composed_label\n",
    "\n",
    "SUBJ = \"p1\"\n",
    "HEMI = \"lh\"\n",
    "LAYER = 5\n",
    "DIR_OUT = \"/data/pt_01880/zzz_new\"\n",
    "\n",
    "# make output folders\n",
    "DIR_DENSE = Path(DIR_OUT) / \"dense\"\n",
    "DIR_FLAT = Path(DIR_OUT) / \"flat\"\n",
    "DIR_DENSE.mkdir(parents=True, exist_ok=True)\n",
    "DIR_FLAT.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 294596/294596 [10:39<00:00, 460.93it/s]\n"
     ]
    }
   ],
   "source": [
    "# get final transformation label to dense freesurfer mesh\n",
    "file_out = DIR_DENSE / f\"{HEMI}.composed.label\"\n",
    "file_in = Path(DIR_BASE) / SUBJ / \"anatomy/dense_refined\" / f\"{HEMI}.white_match_final\"\n",
    "file_in2 = Path(DIR_BASE) / SUBJ / \"anatomy/gbb\" / f\"{HEMI}.white_def2_refined\"\n",
    "file_ind2 = Path(DIR_BASE) / SUBJ / \"anatomy/gbb\" / f\"{HEMI}.white_def2_refined_ind.txt\"\n",
    "file_ind3 = Path(DIR_BASE) / SUBJ / \"anatomy/dense_epi\" / f\"{HEMI}.white_def2_ind\"\n",
    "get_composed_label(file_out, file_in, file_in2, file_ind2, file_ind3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/pt_01880/source/miniconda3/envs/odc/lib/python3.10/site-packages/nibabel/spatialimages.py:495: UserWarning: Using large vector Freesurfer hack; header will not be compatible with SPM or FSL\n",
      "  hdr.set_data_shape(shape)\n"
     ]
    }
   ],
   "source": [
    "# transform arrays\n",
    "file_ind = DIR_DENSE / f\"{HEMI}.composed.label\"\n",
    "file_geom = Path(DIR_BASE) / SUBJ / \"anatomy/dense\" / f\"{HEMI}.white\"\n",
    "file_mgh = []\n",
    "for sess in SESSION[SUBJ]:\n",
    "    for day in SESSION[SUBJ][sess]:\n",
    "        if \"_uncorrected\" not in sess:\n",
    "            file_mgh.append(\n",
    "                Path(DIR_BASE) \n",
    "                / SUBJ \n",
    "                / f\"odc/results/Z/sampled/Z_all_left_right_{sess}{day}\" \n",
    "                / f\"{HEMI}.Z_all_left_right_{sess}{day}_layer_{LAYER}.mgh\"\n",
    "            )\n",
    "\n",
    "ind = read_label(file_ind)\n",
    "vtx, _ = read_geometry(file_geom)\n",
    "for f in file_mgh:\n",
    "    file_out = DIR_DENSE / f\"{Path(f).stem}_dense.mgh\"\n",
    "    arr, _, _ = read_mgh(f)\n",
    "    res = np.zeros(len(vtx))\n",
    "    res[ind] = arr\n",
    "    write_mgh(file_out, res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform label\n",
    "file_ind = DIR_DENSE / f\"{HEMI}.composed.label\"\n",
    "file_geom = Path(DIR_BASE) / SUBJ / \"/data/pt_01880/Experiment1_ODC/p1/anatomy/dense/lh.white\"\n",
    "file_label = []\n",
    "for label in [\"fov\", \"v1\", \"v2\", \"v2a\", \"v2b\", \"v3\", \"v3a\", \"v3b\"]:\n",
    "    file_label.append(Path(DIR_BASE) / SUBJ / \"anatomy/label\" / f\"{HEMI}.{label}.label\")\n",
    "\n",
    "ind = read_label(file_ind)\n",
    "for f in file_label:\n",
    "    file_out = DIR_DENSE / f\"{Path(f).stem}_dense.label\"\n",
    "    l_ = read_label(f)\n",
    "    res = ind[l_]\n",
    "    write_label(file_out, res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/pt_01880/source/miniconda3/envs/odc/lib/python3.10/site-packages/nibabel/spatialimages.py:495: UserWarning: Using large vector Freesurfer hack; header will not be compatible with SPM or FSL\n",
      "  hdr.set_data_shape(shape)\n"
     ]
    }
   ],
   "source": [
    "# get average maps\n",
    "for sess in SESSION[SUBJ]:\n",
    "    days = SESSION[SUBJ][sess]\n",
    "    if \"_uncorrected\" not in sess:\n",
    "        file_mgh1 = (\n",
    "            DIR_DENSE \n",
    "            / f\"{HEMI}.Z_all_left_right_{sess}{days[0]}_layer_{LAYER}_dense.mgh\"\n",
    "        )\n",
    "        file_mgh2 = (\n",
    "            DIR_DENSE\n",
    "            / f\"{HEMI}.Z_all_left_right_{sess}{days[1]}_layer_{LAYER}_dense.mgh\"\n",
    "        )\n",
    "        file_out = DIR_DENSE / f\"{HEMI}.Z_all_left_right_{sess}_layer_{LAYER}_avg.mgh\"\n",
    "        arr1, _, _ = read_mgh(file_mgh1)\n",
    "        arr2, _, _ = read_mgh(file_mgh2)\n",
    "        res = (arr1 + arr2) / 2\n",
    "        write_mgh(file_out, res) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sort faces: 1.0 %\n",
      "sort faces: 2.0 %\n",
      "sort faces: 3.0 %\n",
      "sort faces: 4.0 %\n",
      "sort faces: 5.0 %\n",
      "sort faces: 6.0 %\n",
      "sort faces: 7.0 %\n",
      "sort faces: 8.0 %\n",
      "sort faces: 9.0 %\n",
      "sort faces: 10.0 %\n",
      "sort faces: 11.0 %\n",
      "sort faces: 12.0 %\n",
      "sort faces: 13.0 %\n",
      "sort faces: 14.0 %\n",
      "sort faces: 15.0 %\n",
      "sort faces: 16.0 %\n",
      "sort faces: 17.0 %\n",
      "sort faces: 18.0 %\n",
      "sort faces: 19.0 %\n",
      "sort faces: 20.0 %\n",
      "sort faces: 21.0 %\n",
      "sort faces: 22.0 %\n",
      "sort faces: 23.0 %\n",
      "sort faces: 24.0 %\n",
      "sort faces: 25.0 %\n",
      "sort faces: 26.0 %\n",
      "sort faces: 27.0 %\n",
      "sort faces: 28.0 %\n",
      "sort faces: 29.0 %\n",
      "sort faces: 30.0 %\n",
      "sort faces: 31.0 %\n",
      "sort faces: 32.0 %\n",
      "sort faces: 33.0 %\n",
      "sort faces: 34.0 %\n",
      "sort faces: 35.0 %\n",
      "sort faces: 36.0 %\n",
      "sort faces: 37.0 %\n",
      "sort faces: 38.0 %\n",
      "sort faces: 39.0 %\n",
      "sort faces: 40.0 %\n",
      "sort faces: 41.0 %\n",
      "sort faces: 42.0 %\n",
      "sort faces: 43.0 %\n",
      "sort faces: 44.0 %\n",
      "sort faces: 45.0 %\n",
      "sort faces: 46.0 %\n",
      "sort faces: 47.0 %\n",
      "sort faces: 48.0 %\n",
      "sort faces: 49.0 %\n",
      "sort faces: 50.0 %\n",
      "sort faces: 51.0 %\n",
      "sort faces: 52.0 %\n",
      "sort faces: 53.0 %\n",
      "sort faces: 54.0 %\n",
      "sort faces: 55.0 %\n",
      "sort faces: 56.0 %\n",
      "sort faces: 57.0 %\n",
      "sort faces: 58.0 %\n",
      "sort faces: 59.0 %\n",
      "sort faces: 60.0 %\n",
      "sort faces: 61.0 %\n",
      "sort faces: 62.0 %\n",
      "sort faces: 63.0 %\n",
      "sort faces: 64.0 %\n",
      "sort faces: 65.0 %\n",
      "sort faces: 66.0 %\n",
      "sort faces: 67.0 %\n",
      "sort faces: 68.0 %\n",
      "sort faces: 69.0 %\n",
      "sort faces: 70.0 %\n",
      "sort faces: 71.0 %\n",
      "sort faces: 72.0 %\n",
      "sort faces: 73.0 %\n",
      "sort faces: 74.0 %\n",
      "sort faces: 75.0 %\n",
      "sort faces: 76.0 %\n",
      "sort faces: 77.0 %\n",
      "sort faces: 78.0 %\n",
      "sort faces: 79.0 %\n",
      "sort faces: 80.0 %\n",
      "sort faces: 81.0 %\n",
      "sort faces: 82.0 %\n",
      "sort faces: 83.0 %\n",
      "sort faces: 84.0 %\n",
      "sort faces: 85.0 %\n",
      "sort faces: 86.0 %\n",
      "sort faces: 87.0 %\n",
      "sort faces: 88.0 %\n",
      "sort faces: 89.0 %\n",
      "sort faces: 90.0 %\n",
      "sort faces: 91.0 %\n",
      "sort faces: 92.0 %\n",
      "sort faces: 93.0 %\n",
      "sort faces: 94.0 %\n",
      "sort faces: 95.0 %\n",
      "sort faces: 96.0 %\n",
      "sort faces: 97.0 %\n",
      "sort faces: 98.0 %\n",
      "sort faces: 99.0 %\n"
     ]
    }
   ],
   "source": [
    "# get banpass filtered contrast\n",
    "file_geom = Path(DIR_BASE) / SUBJ / \"anatomy/dense\" / f\"{HEMI}.white\"\n",
    "file_label = DIR_DENSE / f\"{HEMI}.v1_dense.label\"\n",
    "file_mgh = DIR_DENSE / f\"{HEMI}.Z_all_left_right_GE_EPI_layer_5_avg.mgh\"\n",
    "vtx, fac = read_geometry(file_geom)\n",
    "label = read_label(file_label)\n",
    "arr, _, _ = read_mgh(file_mgh)\n",
    "mesh = Mesh(vtx, fac)\n",
    "surf_roi = mesh.remove_vertices(label)\n",
    "verts = surf_roi[0]\n",
    "faces = surf_roi[1]\n",
    "for filter_size in [0.025, 0.1, 2.0]:\n",
    "    filt = LaplacianGaussian(verts, faces, filter_size)\n",
    "    tmp = filt.apply(arr[label])\n",
    "    res = np.zeros(len(vtx))\n",
    "    res[label] = tmp\n",
    "    file_out = DIR_DENSE / f\"{Path(file_mgh).stem}_bandpass_{filter_size}.mgh\"\n",
    "    write_mgh(file_out, res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/pt_01880/source/miniconda3/envs/odc/lib/python3.10/site-packages/nibabel/analyze.py:401: UserWarning: Using large vector Freesurfer hack; header will not be compatible with SPM or FSL\n",
      "  obj.set_data_shape(header.get_data_shape())\n",
      "/data/pt_01880/source/miniconda3/envs/odc/lib/python3.10/site-packages/nibabel/spatialimages.py:495: UserWarning: Using large vector Freesurfer hack; header will not be compatible with SPM or FSL\n",
      "  hdr.set_data_shape(shape)\n"
     ]
    }
   ],
   "source": [
    "# project to patch\n",
    "file_out = DIR_FLAT / f\"{HEMI}.flat\"\n",
    "file_patch = \"/data/pt_01880/Experiment1_ODC/p1/anatomy/flat/lh.flat.patch.flat\"\n",
    "patch_as_mesh(file_out, file_patch)\n",
    "\n",
    "file_mgh = DIR_DENSE.glob(\"*.mgh\")\n",
    "for f_in in file_mgh:\n",
    "    f_out = DIR_FLAT / f_in.name\n",
    "    mgh_to_patch(f_out, f_in, file_patch)\n",
    "\n",
    "file_out = DIR_FLAT / f\"{HEMI}.curv\"\n",
    "file_in = Path(DIR_BASE) / SUBJ / \"anatomy/dense\" / f\"{HEMI}.curv\"\n",
    "curv_to_patch(file_out, file_in, file_patch)\n",
    "\n",
    "label = [\"v1\", \"v2\", \"v2a\", \"v2b\", \"v3\", \"v3a\", \"v3b\"]\n",
    "for l_ in label:\n",
    "    f_out = DIR_FLAT / f\"{HEMI}.{l_}_flat.label\"\n",
    "    f_in = DIR_DENSE / f\"{HEMI}.{l_}_dense.label\"\n",
    "    label_to_patch(f_out, f_in, file_patch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "odc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
