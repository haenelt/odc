{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear versus quadratic model estimation\n",
    "# hollander et al., 2021\n",
    "# test for decoding accuracy\n",
    "# increase linearly or show a clear peak at a specific cortical depth\n",
    "# perform bayesian model comparison\n",
    "\n",
    "# fit two hierarhical linear models using pymc\n",
    "# NUTS sampler\n",
    "\n",
    "# dependent variable (decoding accuracy) was first modeled as a linear function of cortical depth\n",
    "# y_n = theta_n,0 + theta_n,1 * d_n\n",
    "\n",
    "# and then also as a quadratic function of cortical depth\n",
    "# y_n = theta_n,0 + theta_n,1 * d_n * theta_n,2 * d^2\n",
    "\n",
    "# where y_n were all observationf for subjects n\n",
    "# d is a corresponding vector of cortical depths\n",
    "# theta_n is the parameter vector for subject n that was estimated\n",
    "\n",
    "# the subject-wise parameters were modeled as coming from Gaussian group distirbution mean mu and standard deviation sigma\n",
    "# theta ~ N(mu, sigma)\n",
    "# mu ~ N(0, 1)\n",
    "# sigma ~ HalfCauchy(5) -> 5 subjects?\n",
    "\n",
    "# (1) use the state-of-the-art Watanabe-Akaike informatoin criterion to do Bayesian model copmarison between the linear and quadratic models\n",
    "# (2) estimate the posterior of the peak of the quadratic function using the formula "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "import numpy as np\n",
    "from src.config import SUBJECTS, SESSION, N_LAYER\n",
    "\n",
    "def get_profile(subj, sess, day):\n",
    "    path = Path(DIR_DATA) / subj / f\"{sess}{SESSION[subj][sess][day]}\"\n",
    "    file = path / \"bandpass_none\" / \"accuracy.csv\"\n",
    "    data = np.genfromtxt(file, delimiter=',')\n",
    "    return data\n",
    "\n",
    "SESS = \"GE_EPI\"\n",
    "DIR_DATA = \"/data/pt_01880/Experiment1_ODC/paper/decoding\"\n",
    "\n",
    "x = []\n",
    "y = []\n",
    "group = []\n",
    "for i, subj in enumerate(SUBJECTS):\n",
    "    for day in [0, 1]:\n",
    "        x.extend(np.reshape(np.repeat(np.arange(N_LAYER),10), (11, 10)).flatten())\n",
    "        y.extend(get_profile(subj, SESS, day).flatten())\n",
    "        group.extend(i * np.ones_like(get_profile(subj, SESS, day).flatten(), dtype=np.int64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "/data/pt_01880/source/miniconda3/envs/odc_review/lib/python3.10/site-packages/pytensor/tensor/elemwise.py:752: RuntimeWarning: invalid value encountered in log\n",
      "  variables = ufunc(*ufunc_args, **ufunc_kwargs)\n",
      "/data/pt_01880/source/miniconda3/envs/odc_review/lib/python3.10/site-packages/pytensor/tensor/elemwise.py:752: RuntimeWarning: invalid value encountered in log\n",
      "  variables = ufunc(*ufunc_args, **ufunc_kwargs)\n",
      "/data/pt_01880/source/miniconda3/envs/odc_review/lib/python3.10/site-packages/pytensor/tensor/elemwise.py:752: RuntimeWarning: invalid value encountered in log\n",
      "  variables = ufunc(*ufunc_args, **ufunc_kwargs)\n",
      "Multiprocess sampling (5 chains in 4 jobs)\n",
      "NUTS: [mu_theta0, mu_theta1, sigma_theta0, sigma_theta1, beta, sigma_bold, sigma_margin]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 5 chains for 500 tune and 10_000 draw iterations (2_500 + 50_000 draws total) took 157 seconds.\n",
      "There were 69 divergences after tuning. Increase `target_accept` or reparameterize.\n"
     ]
    }
   ],
   "source": [
    "import pymc as pm\n",
    "\n",
    "\n",
    "n_group = 5\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "with pm.Model():\n",
    "    # hyperpriors\n",
    "    # sigma: model the uncertainty of our parent distributions\n",
    "    mu_theta0 = pm.Normal(\"mu_theta0\", 0, 1)\n",
    "    mu_theta1 = pm.Normal(\"mu_theta1\", 0, 1)\n",
    "    sigma_theta0 = pm.HalfCauchy(\"sigma_theta0\", 5)\n",
    "    sigma_theta1 = pm.HalfCauchy(\"sigma_theta1\", 5)\n",
    "\n",
    "    theta0 = pm.Gamma(\"theta0\", mu_theta0, sigma_theta0, shape=n_group)\n",
    "    theta1 = pm.Gamma(\"theta1\", mu_theta1, sigma_theta1, shape=n_group)\n",
    "    sigma_margin = pm.Exponential(\"sigma_margin\", 0.1)\n",
    "\n",
    "    y_est = theta0[group] + theta1[group] * x\n",
    "    y_like = pm.Normal(\n",
    "        \"y_like\",\n",
    "        mu=y_est,\n",
    "        sigma=sigma_margin,\n",
    "        observed=y,\n",
    "    )\n",
    "\n",
    "    trace = pm.sample(\n",
    "        draws=10000,\n",
    "        tune=500,\n",
    "        chains=5,\n",
    "        progressbar=True,\n",
    "        target_accept=0.95,\n",
    "        return_inferencedata=True,\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "odc_review",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
